{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports \n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "team_handles = {'Toronto Raptors': 'TOR',\n",
    "                     'Boston Celtics': 'BOS',\n",
    "                     'Philadelphia 76ers': 'PHI',\n",
    "                     'Cleveland Cavaliers': 'CLE',\n",
    "                     'Indiana Pacers': 'IND',\n",
    "                     'Miami Heat': 'MIA',\n",
    "                     'Milwaukee Bucks': 'MIL',\n",
    "                     'Washington Wizards': 'WAS',\n",
    "                     'Detroit Pistons': 'DET',\n",
    "                     'Charlotte Hornets': 'CHO',\n",
    "                     'New York Knicks': 'NYK',\n",
    "                     'Brooklyn Nets': 'BRK',\n",
    "                     'Chicago Bulls': 'CHI',\n",
    "                     'Orlando Magic': 'ORL',\n",
    "                     'Atlanta Hawks': 'ATL',\n",
    "                     'Houston Rockets': 'HOU',\n",
    "                     'Golden State Warriors': 'GSW',\n",
    "                     'Portland Trail Blazers': 'POR',\n",
    "                     'Oklahoma City Thunder': 'OKC',\n",
    "                     'Utah Jazz': 'UTA',\n",
    "                     'New Orleans Pelicans': 'NOP',\n",
    "                     'San Antonio Spurs': 'SAS',\n",
    "                     'Minnesota Timberwolves': 'MIN',\n",
    "                     'Denver Nuggets': 'DEN',\n",
    "                     'Los Angeles Clippers': 'LAC',\n",
    "                     'Los Angeles Lakers': 'LAL',\n",
    "                     'Sacramento Kings': 'SAC',\n",
    "                     'Dallas Mavericks': 'DAL',\n",
    "                     'Memphis Grizzlies': 'MEM',\n",
    "                     'Phoenix Suns': 'PHO'}\n",
    "\n",
    "# HELPER FUNCTIONS\n",
    "\n",
    "# Clean date to calculated date format for webscraping\n",
    "def clean_date(date):\n",
    "    formatted_date = date.replace('-', '')\n",
    "    return formatted_date\n",
    "\n",
    "# INPUT: csv_file name as str, df that needs saved\n",
    "def save_df(csv_name, df):\n",
    "    compression_opts = dict(method='zip',\n",
    "                        archive_name=csv_name+'.csv')\n",
    "\n",
    "    df.to_csv(csv_name+'.zip', index=False, compression=compression_opts)\n",
    "    return 'Saved'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the current season game info by importing team handle and year (2021)\n",
    "\n",
    "def get_current_season_game_info(team_handle):\n",
    "    season_page = requests.get(f'https://www.basketball-reference.com/teams/{team_handle}/2021_games.html')\n",
    "    season_page = BeautifulSoup(season_page.text, 'html.parser')\n",
    "\n",
    "    stats = ['date_game', 'game_start_time', 'network', 'opp_name', 'game_result', 'overtimes', 'pts', 'opp_pts', 'wins', 'losses', 'game_streak']\n",
    "    stats_list = [[td.getText() for td in season_page.findAll('td', {'data-stat': stat})] for stat in stats]\n",
    "    \n",
    "    box_scores = []\n",
    "    dates = []\n",
    "    \n",
    "    for row in season_page.find('table', {'id': 'games'}).tbody.find_all('tr'):\n",
    "        _class = row.get(\"class\")\n",
    "\n",
    "        #skip table body header\n",
    "        if _class is not None and \"thead\" == _class[0]:\n",
    "            continue\n",
    "            \n",
    "        game_result = row.find('td', {'data-stat': 'game_result'}).getText()\n",
    "        \n",
    "        # if there isnt a game result yet, the game has not played and we dont need that info\n",
    "        if game_result == '':\n",
    "            return stats_list, box_scores, dates\n",
    "        \n",
    "        # only get every teams home game so we do not have duplicates\n",
    "        game_loc = row.find('td', {'data-stat': 'game_location'}).getText()\n",
    "        if game_loc == '':\n",
    "            box_score = row.find('td', {'data-stat': 'box_score_text'}).find('a')['href']\n",
    "            box_scores.append(box_score)\n",
    "            date = row.find('td', {'data-stat': 'date_game'})['csk']\n",
    "            dates.append(date)\n",
    "    return stats_list, box_scores, dates\n",
    "\n",
    "\n",
    "# function to get box score stats of advanced and basic with gid=/boxscores/201903010ATL.html\n",
    "def get_box_score_stats(gid):\n",
    "    box_score_page = requests.get(f'https://www.basketball-reference.com/{gid}')\n",
    "    box_score_page = BeautifulSoup(box_score_page.text, 'html.parser')\n",
    "    bs_page_teams = []\n",
    "    bs_page_score = []\n",
    "    \n",
    "    # get team names \n",
    "    for item in box_score_page.find('div', attrs={'class', 'scorebox'}).find_all('strong'):\n",
    "        team_slug = team_handles[item.text.replace('\\n', '')]\n",
    "        bs_page_teams.append(team_slug.lower())\n",
    "    \n",
    "    # get teams score\n",
    "    for score in box_score_page.find('div', attrs={'class', 'scorebox'}).find_all('div', attrs={'class', 'score'}):\n",
    "        bs_page_score.append(score.getText())\n",
    "    \n",
    "    box_score_data = []\n",
    "    advanced_score_data = []\n",
    "    tables = box_score_page.find_all(\"table\")\n",
    "    for i, table in enumerate(tables, start=1):\n",
    "        for td in table.find_all('tfoot'):\n",
    "            box_stats1 = ['mp', 'fg', 'fga', 'fg_pct', 'fg3', 'fg3a', 'fg3_pct', 'ft', 'fta', 'ft_pct', 'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf', 'pts']\n",
    "            advanced_stats = ['ts_pct', 'efg_pct', 'fg3a_per_fga_pct', 'fta_per_fga_pct', 'orb_pct', 'drb_pct', 'trb_pct', 'ast_pct', 'stl_pct', 'blk_pct', 'tov_pct','usg_pct', 'off_rtg', 'def_rtg']\n",
    "            data = [[td1.getText() for td1 in td.findAll('td', {'data-stat': stat})] for stat in box_stats1]\n",
    "            box_score_data.append(data)\n",
    "            advanced_score = [[td2.getText() for td2 in td.findAll('td', {'data-stat': a_stat})] for a_stat in advanced_stats]\n",
    "            advanced_score_data.append(advanced_score)\n",
    "    return bs_page_teams, box_score_data, advanced_score_data, bs_page_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210 210 1482 210\n"
     ]
    }
   ],
   "source": [
    "# Processing basketball reference data\n",
    "\n",
    "all_dates = []\n",
    "all_box_scores = []\n",
    "for team in team_handles.values():\n",
    "    stats_list, box_scores, dates = get_current_season_game_info(team)\n",
    "    all_box_scores.append(box_scores)\n",
    "    all_dates.append(dates)\n",
    "\n",
    "\n",
    "\n",
    "final_list_basic = []\n",
    "final_list_advanced = []\n",
    "ordered_teams = []\n",
    "ordered_scores = []\n",
    "for team_box_score in all_box_scores:\n",
    "    for box_score in team_box_score:\n",
    "        teams, b_score_data, a_score_data, scores = get_box_score_stats(box_score)\n",
    "\n",
    "        # order score data\n",
    "        for score in scores:\n",
    "            ordered_scores.append(score)\n",
    "\n",
    "        # get the basic score data into dataframe ready format\n",
    "        for b in b_score_data:\n",
    "            if b[1] != []:\n",
    "                final_list_basic.append(b)\n",
    "\n",
    "\n",
    "        # get the teams in dataframe format\n",
    "        for team in teams:\n",
    "            ordered_teams.append(team)\n",
    "\n",
    "        # finding data and appending to final_list of data (need to ignore empty columns) for advanced\n",
    "        for a in a_score_data:\n",
    "            if a[-1] != []:\n",
    "                final_list_advanced.append(a)\n",
    "            \n",
    "print(len(ordered_scores), len(ordered_teams), len(final_list_basic), len(final_list_advanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mp  fg fga fg_pct fg3 fg3a fg3_pct  ft fta ft_pct orb drb trb ast stl  \\\n",
      "0   240  42  80   .525  19   42    .452  10  20   .500   8  37  45  30  13   \n",
      "7   240  38  89   .427  14   46    .304   9  12   .750   7  28  35  26  10   \n",
      "14  240  32  88   .364   3   36    .083  16  20   .800   9  39  48  21   6   \n",
      "21  240  34  83   .410  17   52    .327  15  21   .714   9  44  53  21   7   \n",
      "28  240  41  84   .488  15   29    .517  29  34   .853  12  44  56  19   3   \n",
      "\n",
      "   blk tov  pf  pts teams  \n",
      "0    7  24  17  113   nop  \n",
      "7    5  20  22   99   tor  \n",
      "14   3  15  21   83   nyk  \n",
      "21   6  16  22  100   tor  \n",
      "28   9  19  29  126   bos  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-106-20bc897c5734>:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_full_game['teams'] = ordered_teams\n"
     ]
    }
   ],
   "source": [
    "## Putting the data into dataframes\n",
    "\n",
    "advanced_stats_cols = ['ts_pct', 'efg_pct', 'fg3a_per_fga_pct', 'fta_per_fga_pct', 'orb_pct', 'drb_pct', 'trb_pct', 'ast_pct', 'stl_pct', 'blk_pct', 'tov_pct','usg_pct', 'off_rtg', 'def_rtg']\n",
    "box_stats_cols = ['mp', 'fg', 'fga', 'fg_pct', 'fg3', 'fg3a', 'fg3_pct', 'ft', 'fta', 'ft_pct', 'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf', 'pts']\n",
    "\n",
    "\n",
    "# make dataframes have correct value type\n",
    "df = pd.DataFrame(final_list_basic)\n",
    "for i in range(0,19):\n",
    "    df[i] = df[i].str[0]\n",
    "    \n",
    "\n",
    "\n",
    "df1 = pd.DataFrame(final_list_advanced)\n",
    "for i in range(0,14):\n",
    "    df1[i] = df1[i].str[0]\n",
    "    \n",
    "\n",
    "df.columns = box_stats_cols\n",
    "df1.columns = advanced_stats_cols\n",
    "\n",
    "\n",
    "df1['teams'] = ordered_teams\n",
    "df1['score'] = ordered_scores\n",
    "\n",
    "df_dates = []\n",
    "for date in all_dates:\n",
    "    for d in date:\n",
    "        df_dates.append(clean_date(d))\n",
    "\n",
    "        \n",
    "df_full_game = df.loc[(df['mp'].astype(int)>=240)]\n",
    "df_full_game['teams'] = ordered_teams\n",
    "print(df_full_game.head())\n",
    "\n",
    "\n",
    "# for full game join of basic statistics\n",
    "df_full_game_join = df_full_game.join(df_full_game.shift(-1).add_prefix('away_'))\n",
    "df_full_game_join[1::2] = ''\n",
    "df_full_game_join = df_full_game_join[df_full_game_join.mp != '']\n",
    "df_full_game_join['date'] = df_dates\n",
    "df_full_game_join['date'] = df_full_game_join['date'].apply(str)\n",
    "df_full_game_join['key'] = df_full_game_join['date'] + df_full_game_join['teams'] + df_full_game_join['away_teams']\n",
    "\n",
    "\n",
    "\n",
    "# for full join of advanced statistics\n",
    "df_join = df1.join(df1.shift(-1).add_prefix('away_'))\n",
    "df_join[1::2] = ''\n",
    "df_join = df_join[df_join.ts_pct != '']\n",
    "df_join['date'] = df_dates\n",
    "df_join['date'] = df_join['date'].apply(str)\n",
    "df_join['key'] = df_join['date'] + df_join['teams'] + df_join['away_teams']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-114-21e83b8241f3>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_quarters['quarter'] = quarters_halfs\n",
      "<ipython-input-114-21e83b8241f3>:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_quarters['team'] = total_teams\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Saved'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save df for per quareter points\n",
    "df_quarters = df.loc[(df['mp'].astype(int) != 25)]\n",
    "count = 0\n",
    "\n",
    "total_teams = []\n",
    "quarters_halfs = []\n",
    "\n",
    "for team in ordered_teams:\n",
    "    total_teams.append(team)\n",
    "    quarters_halfs.append('game')\n",
    "    total_teams.append(team)\n",
    "    quarters_halfs.append('q1')\n",
    "    total_teams.append(team)\n",
    "    quarters_halfs.append('q2')\n",
    "    total_teams.append(team)\n",
    "    quarters_halfs.append('first_half')\n",
    "    total_teams.append(team)\n",
    "    quarters_halfs.append('q3')\n",
    "    total_teams.append(team)\n",
    "    quarters_halfs.append('q4')\n",
    "    total_teams.append(team)\n",
    "    quarters_halfs.append('second_half')\n",
    "        \n",
    "\n",
    "df_quarters['quarter'] = quarters_halfs\n",
    "df_quarters['team'] = total_teams\n",
    "\n",
    "df_quarters.head(14)\n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "save_df('per_quarter_stats', df_quarters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scrape Lines (can add getting current by not putting dates and can get 1st half, second half, and quarters)\n",
    "\n",
    "# get spreads\n",
    "def get_betting_spreads(date):\n",
    "    info_list = []\n",
    "    betting_page = requests.get(f'https://classic.sportsbookreview.com/betting-odds/nba-basketball/?date={date}')\n",
    "    time.sleep(2)\n",
    "    betting_page = BeautifulSoup(betting_page.text, 'html.parser')\n",
    "    teams_list = []\n",
    "    for row in betting_page.find_all('div', {'class': 'eventLine-value'}):\n",
    "        teams_list.append(row.text)\n",
    "    betting_lines = []\n",
    "    for item in betting_page.find_all('div', {'class': 'event-holder holder-complete'}):\n",
    "        for line in item.find('div', {'class': 'el-div eventLine-book'}):\n",
    "            betting_lines.append(line.text)\n",
    "    betting_lines = [line.replace('\\xa0', ' ') for line in betting_lines]\n",
    "    date_list = [date for item in betting_lines]\n",
    "    zipped_teams_lines = zip(date_list, teams_list, betting_lines)\n",
    "    return list(zipped_teams_lines)\n",
    "\n",
    "# get overs unders\n",
    "def get_betting_totals(date):\n",
    "    info_list = []\n",
    "    betting_page = requests.get(f'https://classic.sportsbookreview.com/betting-odds/nba-basketball/totals/?date={date}')\n",
    "    time.sleep(2)\n",
    "    betting_page = BeautifulSoup(betting_page.text, 'html.parser')\n",
    "    teams_list = []\n",
    "    for row in betting_page.find_all('div', {'class': 'eventLine-value'}):\n",
    "        teams_list.append(row.text)\n",
    "    betting_lines = []\n",
    "    for item in betting_page.find_all('div', {'class': 'event-holder holder-complete'}):\n",
    "        for line in item.find('div', {'class': 'el-div eventLine-book'}):\n",
    "            betting_lines.append(line.text)\n",
    "    betting_lines = [line.replace('\\xa0', ' ') for line in betting_lines]\n",
    "    date_list = [date for item in betting_lines]\n",
    "    zipped_teams_lines = zip(date_list, teams_list, betting_lines)\n",
    "    return list(zipped_teams_lines)\n",
    "\n",
    "# Get money lines\n",
    "def get_betting_money_lines(date):\n",
    "    info_list = []\n",
    "    betting_page = requests.get(f'https://classic.sportsbookreview.com/betting-odds/nba-basketball/money-line/?date={date}')\n",
    "    time.sleep(2)\n",
    "    betting_page = BeautifulSoup(betting_page.text, 'html.parser')\n",
    "    teams_list = []\n",
    "    for row in betting_page.find_all('div', {'class': 'eventLine-value'}):\n",
    "        teams_list.append(row.text)\n",
    "    betting_lines = []\n",
    "    for item in betting_page.find_all('div', {'class': 'event-holder holder-complete'}):\n",
    "        for line in item.find('div', {'class': 'el-div eventLine-book'}):\n",
    "            betting_lines.append(line.text)\n",
    "    betting_lines = [line.replace('\\xa0', ' ') for line in betting_lines]\n",
    "    date_list = [date for item in betting_lines]\n",
    "    zipped_teams_lines = zip(date_list, teams_list, betting_lines)\n",
    "    return list(zipped_teams_lines)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20201223']\n",
      "['20201223', '20201231']\n",
      "['20201223', '20201231', '20210104']\n",
      "['20201223', '20201231', '20210104', '20201225']\n",
      "['20201223', '20201231', '20210104', '20201225', '20201230']\n",
      "['20201223', '20201231', '20210104', '20201225', '20201230', '20201229']\n",
      "['20201223', '20201231', '20210104', '20201225', '20201230', '20201229', '20210102']\n",
      "['20201223', '20201231', '20210104', '20201225', '20201230', '20201229', '20210102', '20201227']\n",
      "['20201223', '20201231', '20210104', '20201225', '20201230', '20201229', '20210102', '20201227', '20210101']\n",
      "['20201223', '20201231', '20210104', '20201225', '20201230', '20201229', '20210102', '20201227', '20210101', '20201226']\n",
      "['20201223', '20201231', '20210104', '20201225', '20201230', '20201229', '20210102', '20201227', '20210101', '20201226', '20210103']\n",
      "['20201223', '20201231', '20210104', '20201225', '20201230', '20201229', '20210102', '20201227', '20210101', '20201226', '20210103', '20201222']\n",
      "['20201223', '20201231', '20210104', '20201225', '20201230', '20201229', '20210102', '20201227', '20210101', '20201226', '20210103', '20201222', '20201228']\n",
      "['20201223', '20201231', '20210104', '20201225', '20201230', '20201229', '20210102', '20201227', '20210101', '20201226', '20210103', '20201222', '20201228', '20210105']\n"
     ]
    }
   ],
   "source": [
    "# Processing line data\n",
    "clean_dates = []\n",
    "for date in all_dates:\n",
    "    for d in date:\n",
    "        if clean_date(d) not in clean_dates:\n",
    "            clean_dates.append(clean_date(d))\n",
    "    \n",
    "\n",
    "all_spreads = []\n",
    "all_money_lines = []\n",
    "all_totals = []\n",
    "for date in clean_dates:\n",
    "    all_spreads.append(get_betting_spreads(date))\n",
    "    all_money_lines.append(get_betting_money_lines(date))\n",
    "    all_totals.append(get_betting_totals(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team abriviations\n",
    "team_abr = {'Toronto': 'TOR',\n",
    "                     'Boston': 'BOS',\n",
    "                     'Philadelphia': 'PHI',\n",
    "                     'Cleveland': 'CLE',\n",
    "                     'Indiana': 'IND',\n",
    "                     'Miami': 'MIA',\n",
    "                     'Milwaukee': 'MIL',\n",
    "                     'Washington': 'WAS',\n",
    "                     'Detroit': 'DET',\n",
    "                     'Charlotte': 'CHO',\n",
    "                     'New York': 'NYK',\n",
    "                     'Brooklyn': 'BRK',\n",
    "                     'Chicago': 'CHI',\n",
    "                     'Orlando': 'ORL',\n",
    "                     'Atlanta': 'ATL',\n",
    "                     'Houston': 'HOU',\n",
    "                     'Golden State': 'GSW',\n",
    "                     'Portland': 'POR',\n",
    "                     'Oklahoma City': 'OKC',\n",
    "                     'Utah': 'UTA',\n",
    "                     'New Orleans': 'NOP',\n",
    "                     'San Antonio': 'SAS',\n",
    "                     'Minnesota': 'MIN',\n",
    "                     'Denver': 'DEN',\n",
    "                     'LA': 'LAC',\n",
    "                     'L.A. Lakers': 'LAL',\n",
    "                     'Sacramento': 'SAC',\n",
    "                     'Dallas': 'DAL',\n",
    "                     'Memphis': 'MEM',\n",
    "                     'Phoenix': 'PHO'}\n",
    "\n",
    "# Processing Totals Data\n",
    "totals_date = []\n",
    "totals_team = []\n",
    "totals_line = []\n",
    "totals_total = []\n",
    "# holds 2 things in it, needs to split\n",
    "total_line = []\n",
    "\n",
    "for d in all_totals:\n",
    "    for game in d:\n",
    "        totals_date.append(game[0])\n",
    "        totals_team.append(game[1])\n",
    "        total_line.append(game[2])\n",
    "\n",
    "# splits the 2 things       \n",
    "for item in total_line:\n",
    "    spl = item.split(' ')\n",
    "    totals_total.append(spl[0])\n",
    "    totals_line.append(spl[1])\n",
    "    \n",
    "totals_team_abr_list = []\n",
    "for t in totals_team:\n",
    "    abr = team_abr.get(t)\n",
    "    totals_team_abr_list.append(abr.lower())\n",
    "    \n",
    "# Processing Spread Data\n",
    "spreads_date = []\n",
    "spreads_team = []\n",
    "spreads_line = []\n",
    "spread = []\n",
    "\n",
    "\n",
    "for d in all_spreads:\n",
    "    for game in d:\n",
    "        spreads_date.append(game[0])\n",
    "        spreads_team.append(game[1])\n",
    "        spreads_line.append(game[2])\n",
    "\n",
    "# splits the 2 things       \n",
    "for item in spreads_line:\n",
    "    spl = item.split(' ')\n",
    "    spread.append(spl[0])\n",
    "        \n",
    "spreads_team_abr_list = []\n",
    "for t in spreads_team:\n",
    "    abr = team_abr.get(t)\n",
    "    spreads_team_abr_list.append(abr.lower())\n",
    "    \n",
    "# Processing Money Line (ml) Data\n",
    "ml_date = []\n",
    "ml_team = []\n",
    "ml_line = []\n",
    "\n",
    "\n",
    "for d in all_money_lines:\n",
    "    for game in d:\n",
    "        ml_date.append(game[0])\n",
    "        ml_team.append(game[1])\n",
    "        ml_line.append(game[2])\n",
    "\n",
    "ml_team_abr_list = []\n",
    "for t in ml_team:\n",
    "    abr = team_abr.get(t)\n",
    "    ml_team_abr_list.append(abr.lower())\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataframes\n",
    "\n",
    "# Totals Dataframe\n",
    "df_totals = pd.DataFrame(list(zip(totals_date, totals_team_abr_list, totals_line)), \n",
    "               columns =['date', 'team', 'line']) \n",
    "\n",
    "df_totals_join = df_totals.join(df_totals.shift(-1).add_prefix('away_'))\n",
    "df_totals_join[1::2] = ''\n",
    "df_totals_join['total'] = totals_total\n",
    "df_totals_join = df_totals_join[df_totals_join.date != '']\n",
    "df_totals_join['date'] = df_totals_join['date'].apply(str)\n",
    "df_totals_join['key'] = df_totals_join['date'] + df_totals_join['team'] + df_totals_join['away_team']\n",
    "\n",
    "\n",
    "# Spreads Dataframe\n",
    "df_spreads = pd.DataFrame(list(zip(spreads_date, spreads_team_abr_list, spread)), \n",
    "               columns =['date', 'team', 'line']) \n",
    "\n",
    "df_spreads_join = df_spreads.join(df_spreads.shift(-1).add_prefix('away_'))\n",
    "df_spreads_join[1::2] = ''\n",
    "df_spreads_join = df_spreads_join[df_spreads_join.date != '']\n",
    "df_spreads_join['date'] = df_spreads_join['date'].apply(str)\n",
    "df_spreads_join['key'] = df_spreads_join['date'] + df_spreads_join['team'] + df_spreads_join['away_team']\n",
    "\n",
    "\n",
    "# ML Dataframe\n",
    "df_ml = pd.DataFrame(list(zip(ml_date,  ml_team_abr_list, ml_line)), \n",
    "               columns =['date', 'team', 'money_line']) \n",
    "\n",
    "df_ml_join = df_ml.join(df_ml.shift(-1).add_prefix('away_'))\n",
    "df_ml_join[1::2] = ''\n",
    "df_ml_join = df_ml_join[df_ml_join.date != ''] \n",
    "df_ml_join['date'] = df_ml_join['date'].apply(str)\n",
    "df_ml_join['key'] = df_ml_join['date'] + df_ml_join['team'] + df_ml_join['away_team']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 105 105 105 105\n"
     ]
    }
   ],
   "source": [
    "print(len(df_totals_join), len(df_spreads_join), len(df_ml_join), len(df_full_game_join), len(df_join))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_x</th>\n",
       "      <th>team_x</th>\n",
       "      <th>line_x</th>\n",
       "      <th>away_date_x</th>\n",
       "      <th>away_team_x</th>\n",
       "      <th>away_line_x</th>\n",
       "      <th>total</th>\n",
       "      <th>key</th>\n",
       "      <th>date_y</th>\n",
       "      <th>team_y</th>\n",
       "      <th>...</th>\n",
       "      <th>away_ast_pct</th>\n",
       "      <th>away_stl_pct</th>\n",
       "      <th>away_blk_pct</th>\n",
       "      <th>away_tov_pct</th>\n",
       "      <th>away_usg_pct</th>\n",
       "      <th>away_off_rtg</th>\n",
       "      <th>away_def_rtg</th>\n",
       "      <th>away_teams_y</th>\n",
       "      <th>away_score</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20201223</td>\n",
       "      <td>cho</td>\n",
       "      <td>-107</td>\n",
       "      <td>20201223</td>\n",
       "      <td>cle</td>\n",
       "      <td>-104</td>\n",
       "      <td>217</td>\n",
       "      <td>20201223chocle</td>\n",
       "      <td>20201223</td>\n",
       "      <td>cho</td>\n",
       "      <td>...</td>\n",
       "      <td>73.9</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6.5</td>\n",
       "      <td>15.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>119.2</td>\n",
       "      <td>112.3</td>\n",
       "      <td>cle</td>\n",
       "      <td>121</td>\n",
       "      <td>20201223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20201223</td>\n",
       "      <td>was</td>\n",
       "      <td>-113</td>\n",
       "      <td>20201223</td>\n",
       "      <td>phi</td>\n",
       "      <td>+102</td>\n",
       "      <td>230½</td>\n",
       "      <td>20201223wasphi</td>\n",
       "      <td>20201223</td>\n",
       "      <td>was</td>\n",
       "      <td>...</td>\n",
       "      <td>53.7</td>\n",
       "      <td>10.4</td>\n",
       "      <td>13.8</td>\n",
       "      <td>13.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>106.9</td>\n",
       "      <td>101.2</td>\n",
       "      <td>phi</td>\n",
       "      <td>113</td>\n",
       "      <td>20201223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20201223</td>\n",
       "      <td>nyk</td>\n",
       "      <td>-104</td>\n",
       "      <td>20201223</td>\n",
       "      <td>ind</td>\n",
       "      <td>-106</td>\n",
       "      <td>215½</td>\n",
       "      <td>20201223nykind</td>\n",
       "      <td>20201223</td>\n",
       "      <td>nyk</td>\n",
       "      <td>...</td>\n",
       "      <td>60.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>15.8</td>\n",
       "      <td>10.9</td>\n",
       "      <td>100.0</td>\n",
       "      <td>114.2</td>\n",
       "      <td>101.0</td>\n",
       "      <td>ind</td>\n",
       "      <td>121</td>\n",
       "      <td>20201223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20201223</td>\n",
       "      <td>mia</td>\n",
       "      <td>-114</td>\n",
       "      <td>20201223</td>\n",
       "      <td>orl</td>\n",
       "      <td>+103</td>\n",
       "      <td>218½</td>\n",
       "      <td>20201223miaorl</td>\n",
       "      <td>20201223</td>\n",
       "      <td>mia</td>\n",
       "      <td>...</td>\n",
       "      <td>54.8</td>\n",
       "      <td>14.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>14.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>107.7</td>\n",
       "      <td>102.0</td>\n",
       "      <td>orl</td>\n",
       "      <td>113</td>\n",
       "      <td>20201223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20201223</td>\n",
       "      <td>mil</td>\n",
       "      <td>+104</td>\n",
       "      <td>20201223</td>\n",
       "      <td>bos</td>\n",
       "      <td>-114</td>\n",
       "      <td>223½</td>\n",
       "      <td>20201223milbos</td>\n",
       "      <td>20201223</td>\n",
       "      <td>mil</td>\n",
       "      <td>...</td>\n",
       "      <td>47.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>122.1</td>\n",
       "      <td>121.1</td>\n",
       "      <td>bos</td>\n",
       "      <td>122</td>\n",
       "      <td>20201223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     date_x team_x line_x away_date_x away_team_x away_line_x total  \\\n",
       "0  20201223    cho   -107    20201223         cle        -104   217   \n",
       "1  20201223    was   -113    20201223         phi        +102  230½   \n",
       "2  20201223    nyk   -104    20201223         ind        -106  215½   \n",
       "3  20201223    mia   -114    20201223         orl        +103  218½   \n",
       "4  20201223    mil   +104    20201223         bos        -114  223½   \n",
       "\n",
       "              key    date_y team_y  ... away_ast_pct away_stl_pct  \\\n",
       "0  20201223chocle  20201223    cho  ...         73.9         11.8   \n",
       "1  20201223wasphi  20201223    was  ...         53.7         10.4   \n",
       "2  20201223nykind  20201223    nyk  ...         60.9          5.7   \n",
       "3  20201223miaorl  20201223    mia  ...         54.8         14.3   \n",
       "4  20201223milbos  20201223    mil  ...         47.9          8.0   \n",
       "\n",
       "  away_blk_pct away_tov_pct away_usg_pct away_off_rtg away_def_rtg  \\\n",
       "0          6.5         15.8        100.0        119.2        112.3   \n",
       "1         13.8         13.8        100.0        106.9        101.2   \n",
       "2         15.8         10.9        100.0        114.2        101.0   \n",
       "3          4.8         14.4        100.0        107.7        102.0   \n",
       "4         10.9          5.4        100.0        122.1        121.1   \n",
       "\n",
       "  away_teams_y away_score      date  \n",
       "0          cle        121  20201223  \n",
       "1          phi        113  20201223  \n",
       "2          ind        121  20201223  \n",
       "3          orl        113  20201223  \n",
       "4          bos        122  20201223  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JOIN ALL THE DATA FRAMES INTO ONE MASSIVE DF WITH ALL LINES AND ALL STATS\n",
    "\n",
    "merge_df = pd.merge(df_totals_join, df_spreads_join, how='left', left_on=['key'], right_on = ['key'])\n",
    "\n",
    "merge_df1 = pd.merge(merge_df, df_ml_join, how='left', left_on=['key'], right_on = ['key'])\n",
    "\n",
    "merge_df2 = pd.merge(merge_df1, df_full_game_join, how='left', left_on=['key'], right_on = ['key'])\n",
    "\n",
    "merge_df3 = pd.merge(merge_df2, df_join, how='left', left_on=['key'], right_on = ['key'])\n",
    "\n",
    "merge_df3.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date_x', 'team_x', 'line_x', 'away_date_x', 'away_team_x',\n",
      "       'away_line_x', 'total', 'key', 'date_y', 'team_y', 'line_y',\n",
      "       'away_date_y', 'away_team_y', 'away_line_y', 'date_x', 'team',\n",
      "       'money_line', 'away_date', 'away_team', 'away_money_line', 'mp', 'fg',\n",
      "       'fga', 'fg_pct', 'fg3', 'fg3a', 'fg3_pct', 'ft', 'fta', 'ft_pct', 'orb',\n",
      "       'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf', 'pts', 'teams_x',\n",
      "       'away_mp', 'away_fg', 'away_fga', 'away_fg_pct', 'away_fg3',\n",
      "       'away_fg3a', 'away_fg3_pct', 'away_ft', 'away_fta', 'away_ft_pct',\n",
      "       'away_orb', 'away_drb', 'away_trb', 'away_ast', 'away_stl', 'away_blk',\n",
      "       'away_tov', 'away_pf', 'away_pts', 'away_teams_x', 'date_y', 'ts_pct',\n",
      "       'efg_pct', 'fg3a_per_fga_pct', 'fta_per_fga_pct', 'orb_pct', 'drb_pct',\n",
      "       'trb_pct', 'ast_pct', 'stl_pct', 'blk_pct', 'tov_pct', 'usg_pct',\n",
      "       'off_rtg', 'def_rtg', 'teams_y', 'score', 'away_ts_pct', 'away_efg_pct',\n",
      "       'away_fg3a_per_fga_pct', 'away_fta_per_fga_pct', 'away_orb_pct',\n",
      "       'away_drb_pct', 'away_trb_pct', 'away_ast_pct', 'away_stl_pct',\n",
      "       'away_blk_pct', 'away_tov_pct', 'away_usg_pct', 'away_off_rtg',\n",
      "       'away_def_rtg', 'away_teams_y', 'away_score', 'date'],\n",
      "      dtype='object')\n",
      "  total             key team money_line away_money_line   mp  fg fga fg_pct  \\\n",
      "0   217  20201223chocle  cho       -154            +139  240  45  90   .500   \n",
      "1  230½  20201223wasphi  was       +254            -295  240  39  85   .459   \n",
      "2  215½  20201223nykind  nyk       +257            -298  240  39  85   .459   \n",
      "3  218½  20201223miaorl  mia       -184            +165  240  42  83   .506   \n",
      "4  223½  20201223milbos  mil       -185            +165  240  46  90   .511   \n",
      "\n",
      "  fg3  ... away_trb_pct away_ast_pct away_stl_pct away_blk_pct away_tov_pct  \\\n",
      "0  16  ...         61.0         73.9         11.8          6.5         15.8   \n",
      "1  13  ...         54.0         53.7         10.4         13.8         13.8   \n",
      "2  12  ...         55.6         60.9          5.7         15.8         10.9   \n",
      "3   7  ...         48.8         54.8         14.3          4.8         14.4   \n",
      "4  14  ...         41.6         47.9          8.0         10.9          5.4   \n",
      "\n",
      "  away_usg_pct away_off_rtg away_def_rtg away_score      date  \n",
      "0        100.0        119.2        112.3        121  20201223  \n",
      "1        100.0        106.9        101.2        113  20201223  \n",
      "2        100.0        114.2        101.0        121  20201223  \n",
      "3        100.0        107.7        102.0        113  20201223  \n",
      "4        100.0        122.1        121.1        122  20201223  \n",
      "\n",
      "[5 rows x 75 columns]\n"
     ]
    }
   ],
   "source": [
    "# CLEAN THE DATA SET\n",
    "print(merge_df3.columns)\n",
    "\n",
    "\n",
    "final_df = merge_df3.drop(columns=['date_x', 'team_x', 'line_x', 'away_date_x', 'teams_x', 'away_line_x', 'date_y', 'team_y', 'line_y',\n",
    "       'away_date_y', 'away_team_y', 'away_line_y', 'date_x', 'away_date', 'away_team', 'away_teams_x', 'teams_y', 'away_teams_y', 'away_mp', 'key'])\n",
    "\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Saved'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_df('current_nba_data', final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Saved'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Getting averages for each team and game\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "basic_cols = ['mp', 'fg', 'fga', 'fg_pct', 'fg3', 'fg3a', 'fg3_pct', 'ft', 'fta', 'ft_pct', 'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf', 'pts']\n",
    "df_full_game[basic_cols] = df_full_game[basic_cols].apply(pd.to_numeric)\n",
    "\n",
    "advanced_cols = ['ts_pct', 'efg_pct', 'fg3a_per_fga_pct', 'fta_per_fga_pct', 'orb_pct',\n",
    "       'drb_pct', 'trb_pct', 'ast_pct', 'stl_pct', 'blk_pct', 'tov_pct',\n",
    "       'usg_pct', 'off_rtg', 'def_rtg', 'score']\n",
    "\n",
    "\n",
    "df1[advanced_cols] = df1[advanced_cols].apply(pd.to_numeric)\n",
    "df_avg_basic_stats = df_full_game.groupby('teams', axis=0).mean().reset_index()\n",
    "\n",
    "df_avg_advanced_stats = df1.groupby('teams', axis=0).mean().reset_index()\n",
    "\n",
    "df_avg_merge = pd.merge(df_avg_basic_stats, df_avg_advanced_stats, how='left', left_on=['teams'], right_on = ['teams'])\n",
    "\n",
    "save_df('current_nba_team_avgs', df_avg_merge)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
